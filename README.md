## Four-Projects
### 1. Forecasting the likelihood of credit card default by a customer.
### 2. Forecasting the popularity of online news articles.
### 3. Prediction of song skips on Spotify using sequential user and acoustic data.
### 4. Stock market price prediction using numerical data and textual data.

Across all four projects, I adhered to standard procedures, including __Exploratory Data Analysis (EDA)__, __Data Cleaning__, __Feature Engineering__, __Model Building__, __Prediction__, and __Model Evaluation__. I utilized various models, such as __Logistic Regression__, __Random Forest__, __Decision Trees__, __XGBoost__, __LightGBM__, and __LSTM__. Additionally, I employed techniques like __Ridge__ and __Lasso__ for regression tasks. To address imbalanced data, I employed methods like __SMOTE__ (Synthetic Minority Over-Sampling Technique) and __BorderLineSMOTE__ to generate synthetic samples. I also utilized __PCA__ (Principal Component Analysis) for dimensionality reduction.


Turning to the results:

In the first project, centered around 'Forecasting the likelihood of credit card default by a customer,' the random forest model achieved the highest accuracy of __0.86__.

In the second project, focused on 'Forecasting the popularity of online news articles,' I tackled both regression and classification tasks. For regression, the LightGBM model achieved a mean absolute error of __768__ and an r2 score of __0.117__. In the classification aspect, the random forest model achieved an accuracy of __0.67__.

The third project, involving 'Prediction of song skips on Spotify using sequential user and acoustic data,' saw the LSTM model attain the highest accuracy of __0.90__.

Lastly, in the fourth project, which aimed at 'Stock market price prediction using numerical data and textual data,' the LSTM model achieved a root mean squared error of __48__.
